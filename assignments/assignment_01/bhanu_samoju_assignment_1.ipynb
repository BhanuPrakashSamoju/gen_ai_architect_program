{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhanuPrakashSamoju/gen_ai_architect_program/blob/main/assignments/assignment_01/bhanu_samoju_assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/sample_data"
      ],
      "metadata": {
        "id": "yHT2EZ6BK8PR"
      },
      "id": "yHT2EZ6BK8PR"
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSqzA7zsLeuA",
        "outputId": "3a20f964-de81-4a10-94d0-f23df918b9b8"
      },
      "id": "qSqzA7zsLeuA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env  requirements.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 -m pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIlE_cuPM--Q",
        "outputId": "0a1e9f7a-15d8-4d71-a879-6e3b8a326f16"
      },
      "id": "nIlE_cuPM--Q",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 1)) (0.3.27)\n",
            "Collecting langgraph==0.6.7 (from -r /content/requirements.txt (line 2))\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-openai==0.3.33 (from -r /content/requirements.txt (line 3))\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-community==0.3.29 (from -r /content/requirements.txt (line 4))\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting duckduckgo-search==8.1.1 (from -r /content/requirements.txt (line 5))\n",
            "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: yfinance==0.2.65 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 6)) (0.2.65)\n",
            "Requirement already satisfied: pydantic==2.11.7 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 7)) (2.11.7)\n",
            "Collecting mlflow==3.3.2 (from -r /content/requirements.txt (line 8))\n",
            "  Downloading mlflow-3.3.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: python-dotenv==1.1.1 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 9)) (1.1.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 1)) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 1)) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 1)) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 1)) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 1)) (6.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph==0.6.7->-r /content/requirements.txt (line 2))\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph==0.6.7->-r /content/requirements.txt (line 2))\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph==0.6.7->-r /content/requirements.txt (line 2))\n",
            "  Downloading langgraph_sdk-0.2.7-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7->-r /content/requirements.txt (line 2)) (3.5.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain==0.3.27->-r /content/requirements.txt (line 1))\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (0.11.0)\n",
            "Collecting requests<3,>=2 (from langchain==0.3.27->-r /content/requirements.txt (line 1))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community==0.3.29->-r /content/requirements.txt (line 4))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search==8.1.1->-r /content/requirements.txt (line 5)) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search==8.1.1->-r /content/requirements.txt (line 5))\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search==8.1.1->-r /content/requirements.txt (line 5)) (5.4.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.65->-r /content/requirements.txt (line 6)) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 7)) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 7)) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 7)) (0.4.1)\n",
            "Collecting mlflow-skinny==3.3.2 (from mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading mlflow_skinny-3.3.2-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.3.2 (from mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading mlflow_tracing-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.16.5)\n",
            "Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.16.1)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading databricks_sdk-0.65.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.36.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.35.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 4)) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.65->-r /content/requirements.txt (line 6)) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance==0.2.65->-r /content/requirements.txt (line 6)) (2025.8.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community==0.3.29->-r /content/requirements.txt (line 4))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community==0.3.29->-r /content/requirements.txt (line 4))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==3.3.2->-r /content/requirements.txt (line 8))\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27->-r /content/requirements.txt (line 1)) (1.33)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7->-r /content/requirements.txt (line 2))\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7->-r /content/requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7->-r /content/requirements.txt (line 2)) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27->-r /content/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27->-r /content/requirements.txt (line 1)) (0.24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance==0.2.65->-r /content/requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27->-r /content/requirements.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27->-r /content/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27->-r /content/requirements.txt (line 1)) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.33->-r /content/requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.47.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7->-r /content/requirements.txt (line 2)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7->-r /content/requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27->-r /content/requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.57b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community==0.3.29->-r /content/requirements.txt (line 4))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow==3.3.2->-r /content/requirements.txt (line 8)) (0.6.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading mlflow-3.3.2-py3-none-any.whl (26.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.3.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.3.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.7-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.65.0-py3-none-any.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.9/705.9 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, primp, ormsgpack, mypy-extensions, marshmallow, gunicorn, graphql-core, typing-inspect, graphql-relay, duckduckgo-search, docker, langgraph-sdk, graphene, dataclasses-json, databricks-sdk, langchain-core, mlflow-tracing, mlflow-skinny, langgraph-checkpoint, langchain-openai, mlflow, langgraph-prebuilt, langgraph, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed databricks-sdk-0.65.0 dataclasses-json-0.6.7 docker-7.1.0 duckduckgo-search-8.1.1 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 langchain-community-0.3.29 langchain-core-0.3.76 langchain-openai-0.3.33 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.7 marshmallow-3.26.1 mlflow-3.3.2 mlflow-skinny-3.3.2 mlflow-tracing-3.3.2 mypy-extensions-1.1.0 ormsgpack-1.10.0 primp-0.15.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4dd19471",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dd19471",
        "outputId": "12232d9c-2685-403e-b6bc-a7a65c6d4877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import yfinance as yf\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, TypedDict, Annotated\n",
        "import operator\n",
        "\n",
        "import mlflow\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# --- Load Environment Variables ---\n",
        "# Make sure to create a .env file with your Azure OpenAI credentials\n",
        "load_dotenv(\"/content/env\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "q-MEs5BWWFwK"
      },
      "id": "q-MEs5BWWFwK",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getenv(\"OPENAI_API_TYPE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YFCQyoGFOkpA",
        "outputId": "b7e2a987-77a9-447f-d9f0-034f0e1ecbca"
      },
      "id": "YFCQyoGFOkpA",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'azure'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"http://20.75.92.162:5000\")"
      ],
      "metadata": {
        "id": "zIXNq4iuWFkS"
      },
      "id": "zIXNq4iuWFkS",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U43Ubma8WX4P"
      },
      "id": "U43Ubma8WX4P",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a93347b0",
      "metadata": {
        "id": "a93347b0"
      },
      "outputs": [],
      "source": [
        "# --- 1. Define the Structured Output Schema using Pydantic ---\n",
        "class SentimentProfile(BaseModel):\n",
        "    \"\"\"Structured sentiment profile for a given company based on recent news.\"\"\"\n",
        "    company_name: str = Field(description=\"The name of the company being analyzed.\")\n",
        "    stock_code: str = Field(description=\"The stock market ticker symbol for the company.\")\n",
        "    news_summary: str = Field(description=\"A concise summary of the key news headlines provided.\")\n",
        "    sentiment: str = Field(description=\"Overall sentiment, classified as 'Positive', 'Negative', or 'Neutral'.\")\n",
        "    people_names: List[str] = Field(description=\"List of names of people mentioned in the news.\")\n",
        "    places_names: List[str] = Field(description=\"List of geographic places or locations mentioned.\")\n",
        "    other_companies_referred: List[str] = Field(description=\"List of other company names mentioned.\")\n",
        "    related_industries: List[str] = Field(description=\"List of industries related to the news content.\")\n",
        "    market_implications: str = Field(description=\"A brief analysis of the potential market implications of the news.\")\n",
        "    confidence_score: float = Field(description=\"A confidence score (0.0 to 1.0) for the sentiment classification.\")\n",
        "\n",
        "# --- 2. Define the State for the Graph ---\n",
        "# The state is a dictionary that will be passed between nodes in the graph.\n",
        "# Each field in the state is updated by a node as the graph progresses.\n",
        "class GraphState(TypedDict):\n",
        "    company_name: str\n",
        "    stock_code: str\n",
        "    news_articles: str\n",
        "    sentiment_profile: SentimentProfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a7f35477",
      "metadata": {
        "id": "a7f35477"
      },
      "outputs": [],
      "source": [
        "# --- 3. Define the Nodes of the Graph ---\n",
        "\n",
        "def find_stocks(search_query):\n",
        "    try:\n",
        "        search_results = yf.Search(search_query) # performing search\n",
        "        if search_results.quotes:\n",
        "            filtered_stocks = [\n",
        "                quote for quote in search_results.quotes if quote['quoteType'] == 'EQUITY' # filtering by 'EQUITY' quoteType\n",
        "            ]\n",
        "            return filtered_stocks\n",
        "        else:\n",
        "            return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error during search: {e}\")\n",
        "        return []\n",
        "\n",
        "def get_stock_code(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    It uses the yfinance library to look up the ticker symbol.\n",
        "    \"\"\"\n",
        "    print(\"---Fetching Stock Code---\")\n",
        "    company_name = state['company_name']\n",
        "    try:\n",
        "\n",
        "        search_results = find_stocks(company_name)\n",
        "        if search_results:\n",
        "            print(f\"Found {len(search_results)} results for {company_name}:\")\n",
        "            # for stock in search_results:\n",
        "            #   print(f\"Name: {stock['longname']}, Ticker: {stock['symbol']}, QuoteType: {stock['quoteType']}\")\n",
        "            top_stock = search_results[0]\n",
        "            stock_code = top_stock['symbol']\n",
        "            print(f\"Found stock code for {company_name}: {stock_code}\")\n",
        "            return {\"stock_code\": stock_code}\n",
        "        else:\n",
        "            print(f\"No stocks found for '{search_term}'.\")\n",
        "\n",
        "        return {\"stock_code\": stock_code}\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching stock code for {company_name}: {e}\")\n",
        "        # If lookup fails, we can fall back to using the company name for news search\n",
        "        return {\"stock_code\": company_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2c21cadb",
      "metadata": {
        "id": "2c21cadb"
      },
      "outputs": [],
      "source": [
        "def fetch_news(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node 2: Fetches recent news for the company using its stock code.\n",
        "    It uses the YahooFinanceNewsTool for fetching news.\n",
        "    \"\"\"\n",
        "    print(\"---Fetching Company News---\")\n",
        "    stock_code = state['stock_code']\n",
        "    company_name = state['company_name']\n",
        "\n",
        "    # Using YahooFinanceNewsTool to fetch news.\n",
        "    news_tool = YahooFinanceNewsTool()\n",
        "\n",
        "    try:\n",
        "        # The YahooFinanceNewsTool takes the stock ticker as input\n",
        "        news = news_tool.run(stock_code)\n",
        "        print(f\"Successfully fetched news for {stock_code}.\")\n",
        "        return {\"news_articles\": news}\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching news for {stock_code}: {e}\")\n",
        "        return {\"news_articles\": \"Could not fetch news.\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a732a569",
      "metadata": {
        "id": "a732a569"
      },
      "outputs": [],
      "source": [
        "def analyze_sentiment(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    It calls the Azure OpenAI model and forces it to return a JSON object\n",
        "    matching the SentimentProfile Pydantic schema.\n",
        "    \"\"\"\n",
        "    print(\"---Analyzing Sentiment with LLM---\")\n",
        "    company_name = state['company_name']\n",
        "    stock_code = state['stock_code']\n",
        "    news_articles = state['news_articles']\n",
        "\n",
        "    print(f\"State Variables: {company_name}, {stock_code}, {news_articles}\")\n",
        "\n",
        "    # Define the prompt template\n",
        "    prompt_template = \"\"\"\n",
        "    You are an expert financial analyst. Your task is to generate a structured sentiment profile\n",
        "    for the company '{company_name}' ({stock_code}) based on the following news articles.\n",
        "\n",
        "    Analyze the provided news content and generate a JSON object with the specified fields.\n",
        "\n",
        "    News Articles:\n",
        "    \"{news_articles}\"\n",
        "\n",
        "    Please provide your analysis in a structured JSON format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Register or load the prompt using MLflow\n",
        "    prompt_name = \"bhanu-sentiment-analysis-prompt\"\n",
        "    try:\n",
        "        # Try to load the latest version of the prompt\n",
        "        prompt = mlflow.genai.load_prompt(f\"prompts:/{prompt_name}/latest\")\n",
        "        print(f\"Loaded existing prompt '{prompt.name}' (version {prompt.version})\")\n",
        "    except Exception:\n",
        "        # If the prompt doesn't exist, register it\n",
        "        print(f\"Prompt '{prompt_name}' not found. Registering a new one.\")\n",
        "        prompt = mlflow.genai.register_prompt(\n",
        "            name=prompt_name,\n",
        "            template=prompt_template,\n",
        "            commit_message=\"Prompt for analyzing market sentiment of a company based on news.\",\n",
        "            tags={\n",
        "                \"task\": \"sentiment analysis\",\n",
        "                \"domain\": \"finance\",\n",
        "                \"model_output\": \"json\",\n",
        "            },\n",
        "        )\n",
        "        print(f\"Registered new prompt '{prompt.name}' (version {prompt.version})\")\n",
        "\n",
        "\n",
        "    # Initialize the Azure Chat Model\n",
        "    llm = AzureChatOpenAI(\n",
        "        azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
        "        openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
        "        openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "        openai_api_type=os.getenv(\"OPENAI_API_TYPE\"),\n",
        "        temperature=0,\n",
        "        # streaming=False,\n",
        "    )\n",
        "\n",
        "    structured_llm = llm.with_structured_output(SentimentProfile)\n",
        "\n",
        "    try:\n",
        "        # print(f\"Prompt is : {prompt.template.format(company_name=company_name, stock_code=stock_code, news_articles=news_articles)}\")\n",
        "        # Invoke the model with the prompt and input variables\n",
        "        profile = structured_llm.invoke(prompt.template.format(company_name=company_name, stock_code=stock_code, news_articles=news_articles))\n",
        "        print(\"Successfully analyzed sentiment.\")\n",
        "        return {\"sentiment_profile\": profile.model_dump()}\n",
        "    except Exception as e:\n",
        "        print(f\"Error during sentiment analysis: {e}\")\n",
        "        return {\"sentiment_profile\": None} # Handle potential errors gracefully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b527faf7",
      "metadata": {
        "id": "b527faf7"
      },
      "outputs": [],
      "source": [
        "# --- 4. Build the Graph ---\n",
        "# We define the workflow and connect the nodes in a specific sequence.\n",
        "\n",
        "# Create a new graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add the nodes to the graph\n",
        "workflow.add_node(\"get_stock_code\", get_stock_code)\n",
        "workflow.add_node(\"fetch_news\", fetch_news)\n",
        "workflow.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
        "\n",
        "workflow.add_edge(START, \"get_stock_code\")\n",
        "workflow.add_edge(\"get_stock_code\", \"fetch_news\")\n",
        "workflow.add_edge(\"fetch_news\", \"analyze_sentiment\")\n",
        "workflow.add_edge(\"analyze_sentiment\", END)\n",
        "\n",
        "# Compile the graph into a runnable object\n",
        "app = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d43d6eb6",
      "metadata": {
        "id": "d43d6eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "d35e6e3c-b3d4-45a8-ebbd-049758896da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting sentiment analysis for: Nvidia\n",
            "---Fetching Stock Code---\n",
            "Found 4 results for Nvidia:\n",
            "Found stock code for Nvidia: NVDA\n",
            "---Fetching Company News---\n",
            "Successfully fetched news for NVDA.\n",
            "---Analyzing Sentiment with LLM---\n",
            "State Variables: Nvidia, NVDA, No news found for company that searched with NVDA ticker.\n",
            "Prompt 'bhanu-sentiment-analysis-prompt' not found. Registering a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/09/17 06:37:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: bhanu-sentiment-analysis-prompt, version 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registered new prompt 'bhanu-sentiment-analysis-prompt' (version 6)\n",
            "Successfully analyzed sentiment.\n",
            "{'company_name': 'Nvidia', 'stock_code': 'NVDA', 'news_articles': 'No news found for company that searched with NVDA ticker.', 'sentiment_profile': {'company_name': 'Nvidia', 'stock_code': 'NVDA', 'news_summary': 'No news found for company that searched with NVDA ticker.', 'sentiment': 'Neutral', 'people_names': [], 'places_names': [], 'other_companies_referred': [], 'related_industries': [], 'market_implications': 'The lack of news suggests stability in the current market perception of Nvidia, with no immediate catalysts for significant price movement.', 'confidence_score': 0.5}}\n",
            "\n",
            "--- Final Sentiment Profile ---\n",
            "{'company_name': 'Nvidia', 'stock_code': 'NVDA', 'news_summary': 'No news found for company that searched with NVDA ticker.', 'sentiment': 'Neutral', 'people_names': [], 'places_names': [], 'other_companies_referred': [], 'related_industries': [], 'market_implications': 'The lack of news suggests stability in the current market perception of Nvidia, with no immediate catalysts for significant price movement.', 'confidence_score': 0.5}\n",
            "🏃 View run Sentiment Analysis for Nvidia at: http://20.75.92.162:5000/#/experiments/543460132042339342/runs/9d8b071919b2445ab0a4b2022ff3601d\n",
            "🧪 View experiment at: http://20.75.92.162:5000/#/experiments/543460132042339342\n",
            "\n",
            "✅ Analysis complete for Nvidia.\n",
            "📈 Run `mlflow ui` in your terminal to view the trace.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Trace(trace_id=tr-11b04ea964a9232621cb51d38c22889b)"
            ],
            "text/html": [
              "\n",
              "<div>\n",
              "  <style scoped>\n",
              "  button {\n",
              "    border: none;\n",
              "    border-radius: 4px;\n",
              "    background-color: rgb(34, 114, 180);\n",
              "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
              "    font-size: 13px;\n",
              "    color: white;\n",
              "    margin-top: 8px;\n",
              "    margin-bottom: 8px;\n",
              "    padding: 8px 16px;\n",
              "    cursor: pointer;\n",
              "  }\n",
              "  button:hover {\n",
              "    background-color: rgb(66, 153, 224);\n",
              "  }\n",
              "  </style>\n",
              "  <button\n",
              "    onclick=\"\n",
              "        const display = this.nextElementSibling.style.display;\n",
              "        const isCollapsed = display === 'none';\n",
              "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
              "\n",
              "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
              "        this.innerText = `${verb} MLflow Trace`;\n",
              "    \"\n",
              "  >Collapse MLflow Trace</button>\n",
              "  <iframe\n",
              "    id=\"trace-renderer\"\n",
              "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
              "    src=\"http://20.75.92.162:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-11b04ea964a9232621cb51d38c22889b&amp;experiment_id=543460132042339342&amp;version=3.3.2\"\n",
              "  />\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "company_to_analyze = \"Nvidia\"\n",
        "inputs = {\"company_name\": company_to_analyze}\n",
        "\n",
        "mlflow.set_experiment(\"Market Sentiment Analysis\")\n",
        "mlflow.langchain.autolog() # Automatically logs all LangChain components\n",
        "\n",
        "with mlflow.start_run(run_name=f\"Sentiment Analysis for {company_to_analyze}\") as run:\n",
        "    print(f\"🚀 Starting sentiment analysis for: {company_to_analyze}\")\n",
        "\n",
        "    # Invoke the graph with the initial input\n",
        "    final_state = app.invoke(inputs)\n",
        "\n",
        "    print(final_state)\n",
        "\n",
        "    result_json = final_state['sentiment_profile']\n",
        "\n",
        "    print(\"\\n--- Final Sentiment Profile ---\")\n",
        "    print(result_json)\n",
        "\n",
        "    # Log the final JSON output as an artifact in MLflow\n",
        "    with open(\"sentiment_profile.json\", \"w\") as f:\n",
        "        f.write(json.dumps(result_json, indent=2))\n",
        "    mlflow.log_artifact(\"sentiment_profile.json\")\n",
        "\n",
        "print(f\"\\n✅ Analysis complete for {company_to_analyze}.\")\n",
        "print(\"📈 Run `mlflow ui` in your terminal to view the trace.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cde448a7",
      "metadata": {
        "id": "cde448a7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}